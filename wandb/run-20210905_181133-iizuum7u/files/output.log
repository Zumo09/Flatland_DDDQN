Weigh and Biases Configuration
global_reward	:	1.385506498892843
invalid_action_penalty	:	-1.8678485807484129
step_penalty	:	-1.2258773441701918
n_episodes	:	2500
env_config	:	0
n_evaluation_episodes	:	25
checkpoint_interval	:	100
eps_start	:	1.0
eps_end	:	0.01
eps_decay	:	0.99
stop_penalty	:	0.0
start_penalty	:	0.0
buffer_size	:	100000
buffer_min_size	:	0
restore_replay_buffer	:	
save_replay_buffer	:	False
batch_size	:	128
gamma	:	0.93
tau	:	0.001
learning_rate	:	8e-05
hidden_size	:	128
update_every	:	8
render	:	False
training_id	:	210905181131
n_agents	:	2
x_dim	:	35
y_dim	:	35
n_cities	:	2
max_rails_between_cities	:	2
max_rails_in_city	:	3
malfunction_rate	:	0.02
seed	:	0
observation_tree_depth	:	2
observation_radius	:	10
observation_max_path_depth	:	30
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
ğŸ’¾ Replay buffer status: 0/100000 experiences
ğŸš‰ Training 2 trains on 35x35 grid for 2500 episodes, evaluating on 25 episodes every 100 episodes. Training id '210905181131'.

ğŸš‚ Episode    0	ğŸ† Score: -0.307 (Avg: -0.993)	ğŸ’¯ Done: 100.00% (Avg:   1.00%)	ğŸ² Epsilon: 0.990 	ğŸ”€ Action Probs: â†» 0.215 â† 0.218 â†‘ 0.190 â†’ 0.228 â—¼ 0.149  	âœ… Eval: score -1.066 done  16.00%




































































































ğŸš‚ Episode  100	ğŸ† Score: -0.561 (Avg: -0.708)	ğŸ’¯ Done: 100.00% (Avg:  48.58%)	ğŸ² Epsilon: 0.362 	ğŸ”€ Action Probs: â†» 0.138 â† 0.227 â†‘ 0.248 â†’ 0.198 â—¼ 0.189  	âœ… Eval: score -0.918 done  34.00%



































































































ğŸš‚ Episode  200	ğŸ† Score: -0.178 (Avg: -0.525)	ğŸ’¯ Done: 100.00% (Avg:  71.62%)	ğŸ² Epsilon: 0.133 	ğŸ”€ Action Probs: â†» 0.075 â† 0.321 â†‘ 0.142 â†’ 0.113 â—¼ 0.349  	âœ… Eval: score -1.136 done   8.00%


































































































