Weigh and Biases Configuration
global_reward	:	1.385506498892843
invalid_action_penalty	:	-1.8678485807484129
step_penalty	:	-1.2258773441701918
n_episodes	:	2500
env_config	:	0
n_evaluation_episodes	:	25
checkpoint_interval	:	100
eps_start	:	1.0
eps_end	:	0.01
eps_decay	:	0.99
stop_penalty	:	0.0
start_penalty	:	0.0
buffer_size	:	100000
buffer_min_size	:	0
restore_replay_buffer	:	
save_replay_buffer	:	False
batch_size	:	128
gamma	:	0.93
tau	:	0.001
learning_rate	:	8e-05
hidden_size	:	128
update_every	:	8
render	:	False
training_id	:	210905181131
n_agents	:	2
x_dim	:	35
y_dim	:	35
n_cities	:	2
max_rails_between_cities	:	2
max_rails_in_city	:	3
malfunction_rate	:	0.02
seed	:	0
observation_tree_depth	:	2
observation_radius	:	10
observation_max_path_depth	:	30
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
💾 Replay buffer status: 0/100000 experiences
🚉 Training 2 trains on 35x35 grid for 2500 episodes, evaluating on 25 episodes every 100 episodes. Training id '210905181131'.

🚂 Episode    0	🏆 Score: -0.307 (Avg: -0.993)	💯 Done: 100.00% (Avg:   1.00%)	🎲 Epsilon: 0.990 	🔀 Action Probs: ↻ 0.215 ← 0.218 ↑ 0.190 → 0.228 ◼ 0.149  	✅ Eval: score -1.066 done  16.00%




































































































🚂 Episode  100	🏆 Score: -0.561 (Avg: -0.708)	💯 Done: 100.00% (Avg:  48.58%)	🎲 Epsilon: 0.362 	🔀 Action Probs: ↻ 0.138 ← 0.227 ↑ 0.248 → 0.198 ◼ 0.189  	✅ Eval: score -0.918 done  34.00%



































































































🚂 Episode  200	🏆 Score: -0.178 (Avg: -0.525)	💯 Done: 100.00% (Avg:  71.62%)	🎲 Epsilon: 0.133 	🔀 Action Probs: ↻ 0.075 ← 0.321 ↑ 0.142 → 0.113 ◼ 0.349  	✅ Eval: score -1.136 done   8.00%


































































































