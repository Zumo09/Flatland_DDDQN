Weigh and Biases Configuration
                    n_episodes	:	2000
                    env_config	:	0
         n_evaluation_episodes	:	25
           checkpoint_interval	:	100
                     eps_start	:	1.0
                       eps_end	:	0.01
                     eps_decay	:	0.998
        invalid_action_penalty	:	-1.0
                  step_penalty	:	-1.5
                 global_reward	:	5.0
                  stop_penalty	:	0.0
                 start_penalty	:	0.0
                   buffer_size	:	100000
               buffer_min_size	:	0
                    batch_size	:	128
                         gamma	:	0.98
                           tau	:	0.001
                 learning_rate	:	8e-05
                 hidden_size_1	:	256
                 hidden_size_2	:	128
                 hidden_size_3	:	32
                  update_every	:	16
                     num_heads	:	2
                        p_head	:	0.5
                   training_id	:	210921153017
                      n_agents	:	3
                         x_dim	:	35
                         y_dim	:	35
                      n_cities	:	2
      max_rails_between_cities	:	2
             max_rails_in_city	:	3
              malfunction_rate	:	0.02
                          seed	:	0
        observation_tree_depth	:	2
    observation_max_path_depth	:	30
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
state size : 63
ðŸš‰ Training 3 trains on 35x35 grid for 2000 episodes, evaluating on 25 episodes every 100 episodes. Training id '210921153017'.
[Experience(state=array([[  0. ,   0. ,  20.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  10.6,   1. ,   2. ,   4.7,   2. ,   2. ,  92. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  19.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  10. ,   1. ,   2. ,   4.4,   2. ,   2. ,  91.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  47.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  34. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  47.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  34.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  83.3,   1. ,   1. ,  54.9,   1. ,   2. ,  40.3,
          2. ,   2. ,  53.6,   3. ,   2. , -12. ,   4. ,   2. , -12. ,
          2. ,   1. ,  54.3,   1. ,   2. ,  39.1,   2. ,   2. ,  53. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  82.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  63.6,   1. ,   2. ,  38.5,   2. ,   2. ,  52.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  44.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 131.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  44.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 131.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  53.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  52.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  52.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  24.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  52.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  25. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  45.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  37.4,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  44.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 131.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  28.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  15.4,   1. ,   2. ,   7.1,   2. ,   2. ,  96.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  27.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.8,   1. ,   2. ,   6.8,   2. ,   2. ,  96.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  13.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   5. ,   1. ,   2. ,  86.1,   2. ,   2. ,   1.9,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  12.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   4.4,   1. ,   2. ,  85.5,   2. ,   2. ,   1.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  48.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  33.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  47.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  34. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  46.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  37. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  46. ,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  37.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  17.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   7.4,   1. ,   2. ,  88.5,   2. ,   2. ,   3.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  16.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   6.8,   1. ,   2. ,  87.9,   2. ,   2. ,   2.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  40.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  22.6,   1. ,   2. ,  34.3,   2. ,   2. , 104. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  39.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  44.4,   1. ,   2. ,  10.4,   2. ,   2. , 103.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  48.4,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  32.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  48.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  33.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,   8.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   2. ,   1. ,   2. ,  83.1,   2. ,   2. ,   0.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   7.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.4,   1. ,   2. ,  82.5,   2. ,   2. ,   0.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  38.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  42.6,   1. ,   2. ,  10.1,   2. ,   2. , 102.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  37.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  40.8,   1. ,   2. ,   9.8,   2. ,   2. , 102.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  28.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  24.6,   1. ,   2. , -12. ,   2. ,   2. ,  44.9,
          3. ,   2. ,  23.9,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  27.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  42.6,   1. ,   2. , -12. ,   2. ,   2. ,   9.1,
          3. ,   2. ,  92.1,   4. ,   2. , -12. ,   3. ,   1. ,  23.6,
          1. ,   2. ,  13.7,   2. ,   2. ,  13.4,   3. ,   2. , -12. ,
          4. ,   2. , -12. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  29.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  24.9,   1. ,   2. , -12. ,   2. ,   2. ,  47.2,
          3. ,   2. ,  24.2,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  28.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  24.6,   1. ,   2. , -12. ,   2. ,   2. ,  44.9,
          3. ,   2. ,  23.9,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  56.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16.6,   1. ,   2. ,  37. ,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  56.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  18. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  32.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.9,   1. ,   2. , -12. ,   2. ,   2. ,  27. ,
          3. ,   2. ,  27.6,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  31.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.6,   1. ,   2. , -12. ,   2. ,   2. ,  26.4,
          3. ,   2. ,  27. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  54.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  21.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  53.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  22. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  16.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   6.8,   1. ,   2. ,  87.9,   2. ,   2. ,   2.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  15.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   6.2,   1. ,   2. ,  87.3,   2. ,   2. ,   2.5,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  42.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.3,   1. ,   2. ,  11.3,   2. ,   2. , 130. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  41.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.2,   1. ,   2. ,  35.8,   2. ,   2. , 104.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  15.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   7.6,   1. ,   2. ,   3.2,   2. ,   2. ,  89. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  14.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   7. ,   1. ,   2. ,   2.9,   2. ,   2. ,  88.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  47.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  35.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  46.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  35.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  46. ,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  37.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  45.7,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  38.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  24.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13. ,   1. ,   2. ,   5.9,   2. ,   2. ,  94.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  23.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  12.4,   1. ,   2. ,   5.6,   2. ,   2. ,  93.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  86.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  63. ,   1. ,   2. ,  55.2,   2. ,   2. ,  64. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  85.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  61.5,   1. ,   2. ,  54.9,   2. ,   2. ,  63.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  37.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  40.8,   1. ,   2. ,   9.8,   2. ,   2. , 102.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  36.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  20.2,   1. ,   2. ,   9.5,   2. ,   2. , 101.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  87.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  81.5,   1. ,   2. ,  57.3,   2. ,   2. ,  56.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  86.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  81.2,   1. ,   2. ,  56.7,   2. ,   2. ,  56.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  44.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 132.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  43.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 132.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  81.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  63. ,   1. ,   2. ,  37.9,   2. ,   2. ,  52.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  80.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  62.4,   1. ,   2. ,  63.3,   2. ,   2. ,  52.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  36.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  20.2,   1. ,   2. ,   9.5,   2. ,   2. , 101.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  35.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19.6,   1. ,   2. ,   9.2,   2. ,   2. , 101. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  32.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  17.8,   1. ,   2. ,   8.3,   2. ,   2. ,  99.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  31.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  17.2,   1. ,   2. ,   8. ,   2. ,   2. ,  98.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  11.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   3.8,   1. ,   2. ,  84.9,   2. ,   2. ,   1.3,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  10.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   3.2,   1. ,   2. ,  84.3,   2. ,   2. ,   1. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  45.4,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  36.8,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  45.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  37.4,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  18.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   9.4,   1. ,   2. ,   4.1,   2. ,   2. ,  90.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  17.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8.8,   1. ,   2. ,   3.8,   2. ,   2. ,  90.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  46.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  36.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  46.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  37. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  56.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  18. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  55.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  18.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.2,   1. ,   2. ,  11.9,   2. ,   2. , 133.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  43.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 131.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,   4.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  -0.1,   1. ,   2. ,  80.7,   2. ,   2. ,  -0.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   3.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  -0.4,   1. ,   2. ,  80.1,   2. ,   2. ,  -1.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.5,   1. ,   2. ,  11.9,   2. ,   2. , 106.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=1, reward=-1.5, next_state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.5,   1. ,   2. ,  11.9,   2. ,   2. , 106.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  23.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11. ,   1. ,   2. ,  92.1,   2. ,   2. ,   4.9,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  22.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  10.4,   1. ,   2. ,  91.5,   2. ,   2. ,   4.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  12.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   4.4,   1. ,   2. ,  85.5,   2. ,   2. ,   1.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  11.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   3.8,   1. ,   2. ,  84.9,   2. ,   2. ,   1.3,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  14.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   7. ,   1. ,   2. ,   2.9,   2. ,   2. ,  88.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  13.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   6.4,   1. ,   2. ,   2.6,   2. ,   2. ,  87.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  19.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8.6,   1. ,   2. ,  89.7,   2. ,   2. ,   3.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  18.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8. ,   1. ,   2. ,  89.1,   2. ,   2. ,   3.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  55.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  55. ,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  13.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   6.4,   1. ,   2. ,   2.6,   2. ,   2. ,  87.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  12.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   5.8,   1. ,   2. ,   2.3,   2. ,   2. ,  87.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  16.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8.2,   1. ,   2. ,   3.5,   2. ,   2. ,  89.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  15.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   7.6,   1. ,   2. ,   3.2,   2. ,   2. ,  89. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  32.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.9,   1. ,   2. , -12. ,   2. ,   2. ,  27. ,
          3. ,   2. ,  27.6,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  32.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.9,   1. ,   2. , -12. ,   2. ,   2. ,  27. ,
          3. ,   2. ,  27.6,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,   7.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.4,   1. ,   2. ,  82.5,   2. ,   2. ,   0.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   6.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.1,   1. ,   2. ,  81.9,   2. ,   2. ,  -0.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  47.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  34.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  47.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  35.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  57.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 131.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  56.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16.2,   1. ,   2. ,  37.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  27.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.8,   1. ,   2. ,   6.8,   2. ,   2. ,  96.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  26.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.2,   1. ,   2. ,   6.5,   2. ,   2. ,  95.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  31.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  26.4,   1. ,   2. , -12. ,   2. ,   2. ,  51.8,
          3. ,   2. ,  24.8,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  30.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  25.8,   1. ,   2. , -12. ,   2. ,   2. ,  49.5,
          3. ,   2. ,  24.5,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  10.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   4.6,   1. ,   2. ,   1.7,   2. ,   2. ,  86. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   9.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   4. ,   1. ,   2. ,   1.4,   2. ,   2. ,  85.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  84.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  80.6,   1. ,   2. ,  55.5,   2. ,   2. ,  54.9,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  83.3,   1. ,   1. ,  54.9,   1. ,   2. ,  40.3,
          2. ,   2. ,  53.6,   3. ,   2. , -12. ,   4. ,   2. , -12. ,
          2. ,   1. ,  54.3,   1. ,   2. ,  39.1,   2. ,   2. ,  53. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.5,   1. ,   2. ,  11.9,   2. ,   2. , 106.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.5,   1. ,   2. ,  11.9,   2. ,   2. , 133.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  26.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.2,   1. ,   2. ,   6.5,   2. ,   2. ,  95.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  25.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,   6.2,   2. ,   2. ,  95. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  22.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11.8,   1. ,   2. ,   5.3,   2. ,   2. ,  93.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  21.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11.2,   1. ,   2. ,   5. ,   2. ,   2. ,  92.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  30.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  25.8,   1. ,   2. , -12. ,   2. ,   2. ,  26.7,
          3. ,   2. ,  24.5,   4. ,   2. , -12. ,   3. ,   1. ,  26.4,
          1. ,   2. , -12. ,   2. ,   2. ,  28.1,   3. ,   2. ,  25.1,
          4. ,   2. , -12. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  31.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  26.4,   1. ,   2. , -12. ,   2. ,   2. ,  51.8,
          3. ,   2. ,  24.8,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  55. ,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  54.7,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  20.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  31.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.6,   1. ,   2. , -12. ,   2. ,   2. ,  26.4,
          3. ,   2. ,  27. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  30.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  25.8,   1. ,   2. , -12. ,   2. ,   2. ,  26.7,
          3. ,   2. ,  24.5,   4. ,   2. , -12. ,   3. ,   1. ,  26.4,
          1. ,   2. , -12. ,   2. ,   2. ,  28.1,   3. ,   2. ,  25.1,
          4. ,   2. , -12. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  19.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  10. ,   1. ,   2. ,   4.4,   2. ,   2. ,  91.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  18.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   9.4,   1. ,   2. ,   4.1,   2. ,   2. ,  90.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,   1.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  -0.4,   1. ,   2. , -12. ,   2. ,   2. , -12. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. ,  64.5,
          1. ,   2. ,  55.5,   2. ,   2. ,  64.6,   3. ,   2. , -12. ,
          4. ,   2. , -12. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  86.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  63. ,   1. ,   2. ,  55.2,   2. ,   2. ,  64. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  20.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   9.2,   1. ,   2. ,  90.3,   2. ,   2. ,   4. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  19.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8.6,   1. ,   2. ,  89.7,   2. ,   2. ,   3.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  22.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  10.4,   1. ,   2. ,  91.5,   2. ,   2. ,   4.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  21.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   9.8,   1. ,   2. ,  90.9,   2. ,   2. ,   4.3,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  41.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.2,   1. ,   2. ,  35.8,   2. ,   2. , 104.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  40.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  22.6,   1. ,   2. ,  34.3,   2. ,   2. , 104. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  32.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.9,   1. ,   2. , -12. ,   2. ,   2. ,  27. ,
          3. ,   2. ,  27.6,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=1, reward=-1.5, next_state=array([[  0. ,   0. ,  32.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.9,   1. ,   2. , -12. ,   2. ,   2. ,  27. ,
          3. ,   2. ,  27.6,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  51.7,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  26.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  51.4,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  26.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  10.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   3.2,   1. ,   2. ,  84.3,   2. ,   2. ,   1. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   9.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   2.6,   1. ,   2. ,  83.7,   2. ,   2. ,   0.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  51.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  50.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  28. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  46.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  35.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  46.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  36.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  41.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.2,   1. ,   2. ,  11. ,   2. ,   2. , 104.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  40.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  22.6,   1. ,   2. ,  10.7,   2. ,   2. , 104. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  27.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  42.6,   1. ,   2. , -12. ,   2. ,   2. ,   9.1,
          3. ,   2. ,  92.1,   4. ,   2. , -12. ,   3. ,   1. ,  23.6,
          1. ,   2. ,  13.7,   2. ,   2. ,  13.4,   3. ,   2. , -12. ,
          4. ,   2. , -12. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  26.3,   1. ,   1. ,  13.1,   1. ,   2. ,  93.9,
          2. ,   2. ,   5.8,   3. ,   2. , -12. ,   4. ,   2. , -12. ,
          2. ,   1. ,  12.8,   1. ,   2. ,  93.9,   2. ,   2. ,   5.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.2,   1. ,   2. ,  11.9,   2. ,   2. , 106.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.2,   1. ,   2. ,  11.9,   2. ,   2. , 133.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  51.4,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  26.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  51.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  27.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  52.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  25. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  52. ,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  25.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  18.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8. ,   1. ,   2. ,  89.1,   2. ,   2. ,   3.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  17.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   7.4,   1. ,   2. ,  88.5,   2. ,   2. ,   3.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  14.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   5.6,   1. ,   2. ,  86.7,   2. ,   2. ,   2.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  13.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   5. ,   1. ,   2. ,  86.1,   2. ,   2. ,   1.9,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  49. ,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  31.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  48.7,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  32.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  85.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  61.5,   1. ,   2. ,  54.9,   2. ,   2. ,  63.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  84.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  56.4,   1. ,   2. ,  54.6,   2. ,   2. ,  62.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  50.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  28. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  50.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  28.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  82.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  63.6,   1. ,   2. ,  38.5,   2. ,   2. ,  52.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  81.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  63. ,   1. ,   2. ,  37.9,   2. ,   2. ,  52.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,   6.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.9,   1. ,   2. ,   0.5,   2. ,   2. ,  83.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   5.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.6,   1. ,   2. ,   0.2,   2. ,   2. ,  83. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  49.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  31. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  49. ,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  31.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  30.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16.6,   1. ,   2. ,   7.7,   2. ,   2. ,  98. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  29.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16. ,   1. ,   2. ,   7.4,   2. ,   2. ,  97.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  53.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  22.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  53.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  24.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11.6,   1. ,   2. ,  92.7,   2. ,   2. ,   5.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  23.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11. ,   1. ,   2. ,  92.1,   2. ,   2. ,   4.9,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,   4.3,   1. ,   1. ,  -0.1,   1. ,   2. , -12. ,
          2. ,   2. ,   3.5,   3. ,   2. ,  83.6,   4. ,   2. , -12. ,
          2. ,   1. ,  82.4,   1. ,   2. ,  57.9,   2. ,   2. ,  57.3,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=0, reward=-1.5, next_state=array([[  0. ,   0. ,   3.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  -0.4,   1. ,   2. , -12. ,   2. ,   2. ,   2.2,
          3. ,   2. ,  83. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  35.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19.6,   1. ,   2. ,   9.2,   2. ,   2. , 101. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  34.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19. ,   1. ,   2. ,   8.9,   2. ,   2. , 100.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  43.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 133.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  43.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  30.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  25.8,   1. ,   2. , -12. ,   2. ,   2. ,  49.5,
          3. ,   2. ,  24.5,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  29.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  24.9,   1. ,   2. , -12. ,   2. ,   2. ,  47.2,
          3. ,   2. ,  24.2,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  31.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  17.2,   1. ,   2. ,   8. ,   2. ,   2. ,  98.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  30.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16.6,   1. ,   2. ,   7.7,   2. ,   2. ,  98. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,   5.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.6,   1. ,   2. ,   0.2,   2. ,   2. ,  83. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   4.3,   1. ,   1. ,  -0.1,   1. ,   2. , -12. ,
          2. ,   2. ,   3.5,   3. ,   2. ,  83.6,   4. ,   2. , -12. ,
          2. ,   1. ,  82.4,   1. ,   2. ,  57.9,   2. ,   2. ,  57.3,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  23.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  12.4,   1. ,   2. ,   5.6,   2. ,   2. ,  93.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  22.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11.8,   1. ,   2. ,   5.3,   2. ,   2. ,  93.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  52.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  52.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  24.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,   2.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   0.9,   1. ,   2. , -12. ,   2. ,   2. , -12. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. ,  82.4,
          1. ,   2. ,  57.9,   2. ,   2. ,  57.3,   3. ,   2. , -12. ,
          4. ,   2. , -12. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  87.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  81.5,   1. ,   2. ,  57.3,   2. ,   2. ,  56.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  85.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  80.9,   1. ,   2. ,  56.1,   2. ,   2. ,  55.5,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  84.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  80.6,   1. ,   2. ,  55.5,   2. ,   2. ,  54.9,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  43.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.9,   1. ,   2. ,  11.6,   2. ,   2. , 131.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  42.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.3,   1. ,   2. ,  11.3,   2. ,   2. , 130. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  29.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16. ,   1. ,   2. ,   7.4,   2. ,   2. ,  97.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  28.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  15.4,   1. ,   2. ,   7.1,   2. ,   2. ,  96.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  43.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 131.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  57.1,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 131.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  43.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  42.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.3,   1. ,   2. ,  11.3,   2. ,   2. , 105.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,   3.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  -0.4,   1. ,   2. ,  80.1,   2. ,   2. ,  -1.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   2.3,   1. ,   1. ,  79.5,   1. ,   2. ,  55.8,
          2. ,   2. ,  65.2,   3. ,   2. , -12. ,   4. ,   2. , -12. ,
          2. ,   1. ,  -1.4,   1. ,   2. , -12. ,   2. ,   2. ,   0.9,
          3. ,   2. ,  66. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  56.8,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16.2,   1. ,   2. ,  37.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  56.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  16.6,   1. ,   2. ,  37. ,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,   7.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   2.8,   1. ,   2. ,   0.8,   2. ,   2. ,  84.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   6.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.9,   1. ,   2. ,   0.5,   2. ,   2. ,  83.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,   9.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   4. ,   1. ,   2. ,   1.4,   2. ,   2. ,  85.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   8.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   3.4,   1. ,   2. ,   1.1,   2. ,   2. ,  84.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,   3.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  -0.4,   1. ,   2. , -12. ,   2. ,   2. ,   2.2,
          3. ,   2. ,  83. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   2.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   0.9,   1. ,   2. , -12. ,   2. ,   2. , -12. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. ,  82.4,
          1. ,   2. ,  57.9,   2. ,   2. ,  57.3,   3. ,   2. , -12. ,
          4. ,   2. , -12. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  17.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8.8,   1. ,   2. ,   3.8,   2. ,   2. ,  90.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  16.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   8.2,   1. ,   2. ,   3.5,   2. ,   2. ,  89.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  21.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11.2,   1. ,   2. ,   5. ,   2. ,   2. ,  92.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  20.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  10.6,   1. ,   2. ,   4.7,   2. ,   2. ,  92. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.5,   1. ,   2. ,  11.9,   2. ,   2. , 133.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  43.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.9,   1. ,   2. ,  11.6,   2. ,   2. , 131.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,   8.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   3.4,   1. ,   2. ,   1.1,   2. ,   2. ,  84.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   7.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   2.8,   1. ,   2. ,   0.8,   2. ,   2. ,  84.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.2,   1. ,   2. ,  11.9,   2. ,   2. , 106.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=1, reward=-1.5, next_state=array([[  0. ,   0. ,  44.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  14.2,   1. ,   2. ,  11.9,   2. ,   2. , 106.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  11.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   5.2,   1. ,   2. ,   2. ,   2. ,   2. ,  86.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  10.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   4.6,   1. ,   2. ,   1.7,   2. ,   2. ,  86. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  21.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   9.8,   1. ,   2. ,  90.9,   2. ,   2. ,   4.3,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  20.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   9.2,   1. ,   2. ,  90.3,   2. ,   2. ,   4. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,   9.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   2.6,   1. ,   2. ,  83.7,   2. ,   2. ,   0.7,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   8.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   2. ,   1. ,   2. ,  83.1,   2. ,   2. ,   0.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  50.5,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  28.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  50.2,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  29.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  55.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  55.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,   6.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   1.1,   1. ,   2. ,  81.9,   2. ,   2. ,  -0.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,   5.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,   0.2,   1. ,   2. ,  81.3,   2. ,   2. ,  -0.5,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  49.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  29.8,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  49.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  30.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  45.7,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  38.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  45.4,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  36.8,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True])), Experience(state=array([[  0. ,   0. ,  49.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  30.4,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  49.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  31. ,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True, False])), Experience(state=array([[  0. ,   0. ,  86.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  81.2,   1. ,   2. ,  56.7,   2. ,   2. ,  56.1,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  85.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  80.9,   1. ,   2. ,  56.1,   2. ,   2. ,  55.5,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  55.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  18.6,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  55.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  19.2,   1. ,   2. ,  11.6,   2. ,   2. , 105.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  43.9,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 132.8,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  43.6,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,  11.6,   2. ,   2. , 133.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  42.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.3,   1. ,   2. ,  11.3,   2. ,   2. , 105.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  41.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  23.2,   1. ,   2. ,  11. ,   2. ,   2. , 104.6,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False,  True])), Experience(state=array([[  0. ,   0. ,  25.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  12.2,   1. ,   2. ,  93.3,   2. ,   2. ,   5.5,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  24.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  11.6,   1. ,   2. ,  92.7,   2. ,   2. ,   5.2,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([False, False])), Experience(state=array([[  0. ,   0. ,  25.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13.6,   1. ,   2. ,   6.2,   2. ,   2. ,  95. ,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), action=2, reward=-1.5, next_state=array([[  0. ,   0. ,  24.3,   1. ,   1. , -12. ,   1. ,   2. ,  -1. ,
          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ,
          2. ,   1. ,  13. ,   1. ,   2. ,   5.9,   2. ,   2. ,  94.4,
          3. ,   2. , -12. ,   4. ,   2. , -12. ,   3. ,   1. , -12. ,
          1. ,   2. ,  -1. ,   2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,
          4. ,   2. ,  -1. ,   4. ,   1. , -12. ,   1. ,   2. ,  -1. ,

          2. ,   2. ,  -1. ,   3. ,   2. ,  -1. ,   4. ,   2. ,  -1. ]]), done=False, mask=array([ True,  True]))]
Traceback (most recent call last):
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\multi_agent_training_4act_bootstrap.py", line 392, in <module>
    train_agent(wandb.config)
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\multi_agent_training_4act_bootstrap.py", line 187, in train_agent
    policy.step(agent_prev_obs[agent], agent_prev_action[agent], all_rewards[agent],
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\components\bdddqn_policy.py", line 80, in step
    self._learn()
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\components\bdddqn_policy.py", line 83, in _learn
    states, actions, rewards, next_states, dones, masks = self.memory.sample()
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\components\bdddqn_policy.py", line 182, in sample
    masks = self.__v_stack([e.mask for e in experiences if e is not None])
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\components\bdddqn_policy.py", line 199, in __v_stack
    sub_dim = len(states[0][0])
TypeError: object of type 'numpy.bool_' has no len()
wandb: Terminal output too large. Logging without processing.