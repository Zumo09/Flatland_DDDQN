Weigh and Biases Configuration
                    n_episodes	:	2000
                    env_config	:	0
         n_evaluation_episodes	:	25
           checkpoint_interval	:	100
                     eps_start	:	1.0
                       eps_end	:	0.01
                     eps_decay	:	0.998
        invalid_action_penalty	:	-1.0
                  step_penalty	:	-1.5
                 global_reward	:	5.0
                  stop_penalty	:	0.0
                 start_penalty	:	0.0
                   buffer_size	:	100000
               buffer_min_size	:	0
                    batch_size	:	128
                         gamma	:	0.98
                           tau	:	0.001
                 learning_rate	:	8e-05
                 hidden_size_1	:	256
                 hidden_size_2	:	128
                 hidden_size_3	:	32
                  update_every	:	16
                     num_heads	:	2
                        p_head	:	0.5
                   training_id	:	210921154747
                      n_agents	:	3
                         x_dim	:	35
                         y_dim	:	35
                      n_cities	:	2
      max_rails_between_cities	:	2
             max_rails_in_city	:	3
              malfunction_rate	:	0.02
                          seed	:	0
        observation_tree_depth	:	2
    observation_max_path_depth	:	30
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator
state size : 63
ðŸš‰ Training 3 trains on 35x35 grid for 2000 episodes, evaluating on 25 episodes every 100 episodes. Training id '210921154747'.
WARNING:tensorflow:Gradients do not exist for variables ['val_0_1/kernel:0', 'val_0_1/bias:0', 'adv_0_1/kernel:0', 'adv_0_1/bias:0', 'val_1_1/kernel:0', 'val_1_1/bias:0', 'adv_1_1/kernel:0', 'adv_1_1/bias:0', 'val_2_1/kernel:0', 'val_2_1/bias:0', 'adv_2_1/kernel:0', 'adv_2_1/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['val_0_1/kernel:0', 'val_0_1/bias:0', 'adv_0_1/kernel:0', 'adv_0_1/bias:0', 'val_1_1/kernel:0', 'val_1_1/bias:0', 'adv_1_1/kernel:0', 'adv_1_1/bias:0', 'val_2_1/kernel:0', 'val_2_1/bias:0', 'adv_2_1/kernel:0', 'adv_2_1/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['val_0_0/kernel:0', 'val_0_0/bias:0', 'adv_0_0/kernel:0', 'adv_0_0/bias:0', 'val_1_0/kernel:0', 'val_1_0/bias:0', 'adv_1_0/kernel:0', 'adv_1_0/bias:0', 'val_2_0/kernel:0', 'val_2_0/bias:0', 'adv_2_0/kernel:0', 'adv_2_0/bias:0'] when minimizing the loss.
Traceback (most recent call last):
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\multi_agent_training_4act_bootstrap.py", line 392, in <module>
    train_agent(wandb.config)
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\multi_agent_training_4act_bootstrap.py", line 187, in train_agent
    policy.step(agent_prev_obs[agent], agent_prev_action[agent], all_rewards[agent],
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\components\bdddqn_policy.py", line 80, in step
    self._learn()
  File "C:\Users\emman\OneDrive\Scuola\Unibo\DL - Deep Learning\Project\Repo\Flatland_DDDQN\components\bdddqn_policy.py", line 112, in _learn
    self.qnetwork_local.fit(np.array(train_states), y={'q_values_' + str(head): np.array(train_targets)},
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\engine\training.py", line 1184, in fit
    tmp_logs = self.train_function(iterator)
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\def_function.py", line 885, in __call__
    result = self._call(*args, **kwds)
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\def_function.py", line 917, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\function.py", line 3038, in __call__
    filtered_flat_args) = self._maybe_define_function(args, kwargs)
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\function.py", line 3459, in _maybe_define_function
    return self._define_function_with_shape_relaxation(
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\function.py", line 3381, in _define_function_with_shape_relaxation
    graph_function = self._create_graph_function(
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\function.py", line 3298, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\framework\func_graph.py", line 1007, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\def_function.py", line 668, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\framework\func_graph.py", line 994, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\engine\training.py:853 train_function  *
        return step_function(self, iterator)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\engine\training.py:842 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:1286 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2849 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:3632 _call_for_each_replica
        return fn(*args, **kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\engine\training.py:835 run_step  **
        outputs = model.train_step(data)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\engine\training.py:791 train_step
        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\optimizer_v2\optimizer_v2.py:522 minimize
        return self.apply_gradients(grads_and_vars, name=name)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\optimizer_v2\optimizer_v2.py:628 apply_gradients
        self._create_all_weights(var_list)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\optimizer_v2\optimizer_v2.py:815 _create_all_weights
        self._create_slots(var_list)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\optimizer_v2\adam.py:117 _create_slots
        self.add_slot(var, 'm')
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\keras\optimizer_v2\optimizer_v2.py:901 add_slot
        weight = tf.Variable(
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\ops\variables.py:268 __call__
        return cls._variable_v2_call(*args, **kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\ops\variables.py:250 _variable_v2_call
        return previous_getter(
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\ops\variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:3547 creator
        return next_creator(**kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\ops\variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:3547 creator
        return next_creator(**kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\ops\variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:3547 creator
        return next_creator(**kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\ops\variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    C:\Users\emman\.conda\envs\main-env\lib\site-packages\tensorflow\python\eager\def_function.py:764 invalid_creator_scope
        raise ValueError(
    ValueError: tf.function-decorated function tried to create variables on non-first call.